\chapter{Teoria cinetica dei gas}

[QUESTO CAPITOLO DEVE ANCORA ESSERE SISTEMATO!!!!]

\section{Modello dei gas ideali}
Nella realt\`a i gas sono composti da tante particelle. Imponiamo alcune condizioni:
\setlength{\leftmargini}{0cm}
\begin{itemize}
\item[$\boxed{\text{Isotropo}}$] Le velocit\`a delle particelle sono equamente distribuite in ogni direzione.
\item[$\boxed{\text{Omogeneo}}$] Le particelle sono equamente distribuite.
\end{itemize}
\setlength{\leftmargini}{0.5cm}
Sia $dn(v)$ il numero di particelle con una data velocit\`a.
\begin{remark}
Se $N$ \`e il numero totale di particelle
\[N=\int dn(v)=\int_0^\infty \dd vndv\]
dove $\dd vn$ \`e in un qualche modo la ``densit\`a delle particelle di una data velocit\`a".
\end{remark}
\begin{remark}
Sia $\vec v$ una qualche velocit\`a.
\[dn(\vec v)\pasgnl={isotropia}dn(v)\frac{d\Omega}{4\pi},\]
dove $d\Omega$ \`e l'\textbf{angolo solido}, cio\`e l'area della ambiguit\`a sulla direzione voluta sulla sfera di raggio 1\footnote{$d\Omega=\sin\theta d\theta d\phi$.}.
\end{remark}

\begin{remark}
Per omogeneit\`a il numero di particelle in un volumetto \`e
\[dn=\frac NVdV=\frac NV dAvdt\cos\theta.\]
\end{remark}

\begin{remark}
L'impulso trasferito alla parete dall'impatto di una particella \`e $\abs{\Delta \vec p}=2mv\cos \theta$.
\end{remark}
\noindent Appurate queste equazioni possiamo scrivere il differenziale della pressione come segue:
\begin{align*}
d^2p=&\frac{dF}{dA}=\frac{\abs{d\vec p}/dt}{dA}=\frac1{dA}\frac1{dt}\abs{d\vec p}_{singola}dn dn(\vec v)\\
=&\frac1{dA}\frac1{dt}{2mv\cos \theta}\quad{\frac{N}V dAvdt\cos \theta}\quad{dn(v)\frac{d\Omega}{4\pi}}=\\
=&N\frac{2mv^2\cos^2\theta}Vdn(v)\frac{d\Omega}{4\pi}.
\end{align*}
Facendo la media su tutte le direzioni troviamo il vero differenziale della pressione:
\begin{align*}
dp=&\int_\Omega d^2p=\frac{mv^2}{2\pi}\frac NVdn(v)\int_0^{2\pi}d\phi\int_0^{\pi/2}\cos^2\theta\sin\theta d\theta=\\
=&\frac13mv^2\frac NVdn(v).
\end{align*}
Integrando ora sui possibili moduli delle velocit\`a troviamo la pressione:
\[p=\frac13m\frac NV\under{\doteqdot \ps{v^2}}{\int_0^\infty v^2dn(v)}.\]

\begin{definition}[Energia cinetica media]
Definiamo l'\textbf{energia cinetica media} come \[\ps{E_K}=\frac12mN\ps{v^2}.\]
\end{definition}
\begin{remark}
Vale la relazione
\[\boxed{\frac12m\ps{v^2}=\frac32 k_b T}\]
\end{remark}
\begin{proof}
Osserviamo che
\[pV=\frac13 mN\ps{v^2},\]
dunque
\[nRT=pV=\frac23\ps{E_K},\]
cio\`e
\[T=\frac 23\frac{\ps{E_K}}{nR}=\frac 23N_a\frac{\ps{E_K}}{NR}=\frac 23\frac{\ps{E_K}}{Nk_b}\]
In conclusione
\[{\frac12m\ps{v^2}=\frac32 k_b T}.\]
\end{proof}

\noindent
Consideriamo ora l'energia interna di questo sistema\footnote{affermare che $U=\ps{E_K}$ corrisponde ad assumere che il gas sia monoatomico.}:
\[U=\ps{E_K}=\frac32nRT=C_VT.\]
In generale $U=E_K+E_P$ per una qualche energia potenziale $E_P$. Per piccoli spostamenti $E_P=(E_P)_0+\frac12kx^2$\ \footnote{regime ragionevole per il tipo di forze che agisce all'interno di materiali.}. Nel caso biatomico per esempio $E_P=\frac12I\omega^2$.
\setlength{\leftmargini}{0cm}
\begin{itemize}
\item[$\boxed{\text{Solido}}$] 6 gradi di libert\`a: 3 potenziali (forze elastiche) e 3 cinetiche.
\item[$\boxed{\text{Gas perf. mono.}}$] 3 gradi di libert\`a, tutti cinetici.
\item[$\boxed{\text{Gas perf. bi.}}$] 5 gradi di libert\`a: 3 cinetici e 2 dalla rotazione \footnote{la rotazione lungo l'asse che congiunge le particelle \`e irrilevante}.
\end{itemize}
\setlength{\leftmargini}{0.5cm}


\begin{fact}[Principio di equipartizione]
Ogni grado di libert\`a contribuisce un addendo $\frac12 RT$ al calore specifico a volume costante.
\end{fact}

\section{Distribuzione delle velocit\`a}
Consideriamo ora un sistema isolato con temperatura costante. Cerchiamo di capire come \`e fatta la distribuzione delle velocit\`a.

Decomponiamo le velocit\`a $\vec v$ in $(v_x,v_y,v_z)$. Notiamo che
\[dn(v_x)=Nf(v_x)dv_x,\]
dove $f$ \`e la densit\`a di probabilit\`a che la componente $x$ sia $v_x$.\\
Per isotropia si ha che
\[dn(v_y)=Nf(v_y)dv_y,\quad dn(v_z)=Nf(v_z)dv_z,\]
dunque
\[dn(\vec v)=N f(v_x)f(v_y)f(v_z)dv_xdv_ydv_z.\]
Sempre per isotropia, in realt\`a $f(v_x)f(v_y)f(v_z)$ \`e una funzione del modulo $v=\sqrt{v_x^2+v_y^2+v_z^2}$, non delle singole componenti.

Segue dunque che
\[f(v)f(0)f(0)=\phi(v)=f(v_x)f(v_y)f(v_z).\]
Dividendo per $f(0)^3$ troviamo
\[\frac{f(v)}{f(0)}=\frac{f(v_x)}{f(0)}\frac{f(v_y)}{f(0)}\frac{f(v_z)}{f(0)}\]
\[\log\frac{f(v)}{f(0)}=\log \frac{f(v_x)}{f(0)}+\log\frac{f(v_y)}{f(0)}+\log\frac{f(v_z)}{f(0)}\]


Per brevit\`a sia $G(v)=\log\frac{f(v)}{f(0)}$, da cui
\[G(v)=G(v_x)+G(v_y)+G(v_z).\]
Derivando per $v_i$ con $i\in\cpa{x,y,z}$ troviamo
\[\frac{G'(v)v_i}v=G'(v_i),\]
si ha dunque che
\[\frac{G'(v)}{v}=\frac{G'(v_x)}{v_x}=\frac{G'(v_y)}{v_y}=\frac{G'(v_z)}{v_z}\doteqdot -2\al\]
Troviamo dunque che
\[G(v_i)=-\al v_i^2+C\leadsto f(v_i)=ae^{-\al v_i^2},\]
dunque
\[\phi(v)=Ae^{-\al (v_x^2+v_y^2+v_z^2)}=Ae^{-\al v^2}.\]
Poich\'e $\phi$ \`e una densit\`a di probabilit\`a\footnote{abbiamo usato il fatto che $\int_{-\infty}^{+\infty}e^{-\al x^2}dx=\sqrt{\frac{\pi}\al}$} si ha che $A=\pa{\frac{\al}\pi}^{3/2}$, cio\`e
\[dn(\vec v)=N\pa{\frac{\al}\pi}^{3/2}e^{-\al v^2} dv_xdv_ydv_z\]

\[dn(v)=\int_\Omega dn(\vec v)=N\int_\Omega \phi(v)dv_xdv_ydv_z=N\int_\Omega \phi(v)v^2dvd\Omega=4\pi N\phi(v)v^2dv\]

\[dn(v)=4N\sqrt{\frac{\al^3}\pi}v^2e^{-\al v^2}dv\]

Cerchiamo di capire chi \`e $\al$. \footnote{$\int_0^\infty x^ne^{-\al x^2}=\frac{\Gamma((n+1)/2)}{2a^{(n+1)/2}}$}
\[\frac{3k_bT}m=\ps{v^2}=\frac{\int_0^\infty v^2dn(v)}{\int_0^\infty dn(v)}=\frac 3{2\al}\leadsto \al=\frac m{2k_b T}.\]
Abbiamo dunque ricavato che
\[dn(v)=N 4\pi\pa{\frac{m}{2\pi k_b T}}^{3/2}v^2\exp\pa{-\frac m{2k_bT}v^2}dv\]
\textbf{Distribuzione di Maxwell-Boltzmann}.

La distribuzione ha un massimo pi\`u o meno quando $\frac {mv^2}{2k_bT}=0$ (non esattamente perch\'e c'\`e il termine $v^2$)

[GRAFICO DI $\dd vn$]

Qualcuno ha provato a misurare se effettivamente la distribuzione \`e questa:
fai girare una ruota velocemente con un buchino e poi metto a contatto la ruota con un tubo da cui viene il gas. Vedendo quante sono arrivate sulle varie parti interne della ruota uno pu\`o capire la distribuzione.

\section{Entropia nel modello statistico}
\begin{definition}[Macro- e Microstati]
Dato un sistema statistico come quello trattato in questo capitolo, un \textbf{microstato} \`e il dato di ogni singola posizione e velocit\`a, un \textbf{macrostato} \`e la classe di microstati con le stesse propriet\`a globali (per esempio volume, temperatura, pressione).
\end{definition}
\begin{fact}
\textbf{Tutti i microstati compatibili con un dato macrostato sono equiprobabili.}
\end{fact}

\begin{remark}
Consideriamo due sistemi. Uno in un macrostato con probabilit\`a $P_1$ di verificarsi ed entropia $S_1$, il secondo con dati analoghi $P_2$ e $S_2$. Notiamo che l'insieme dei due sistemi ha entropia $S_1+S_2$ e la probabilit\`a del macrostato di questo insieme \`e $P_1P_2$. Intuitivamente
\[S\propto \log P\propto \log\Omega,\]
dove $\Omega$ \`e il numero di microstati con lo stesso macrostato.\\
Supponiamo dunque $S=C\log\Omega$.
\end{remark}





Consideriamo la seguente situazione: Una scatola adiabatica con due compartimenti di volume $V/2$. Dentro il primo compartimento si trovano $r$ moli di gas e nel secondo $1-r$ moli, entrambi alla stessa temperatura. Ora rimuoviamo la parete
\[\Delta S=(S_{f_1}-S_{i_1})+(S_{f_2}-S_{i_2})=rR\log\pa{\frac{rV}{V/2}}+(1-r)R\log\pa{\frac{(1-r)V}{V/2}}=\]
\[=R\pa{r\log r+(1-r)\log(1-r)+\log 2}.\]


Consideriamo ora una situazione analoga ma con delle particelle: Nel primo compartimento abbiamo $N/2 -x$ particelle e nel secondo $N/2 +x$.
\[\Omega(N,x)=\binom{N}{x+N/2},\]
da cui
\[S_i=C\log(N!)-\log((N/2-x)!)-\log((N/2+x)!).\]
Applicando l'approssimazione di Stirling $\log(N!)\simeq N\log N$ si ha
\[S_i\simeq -NC\pa{\pa{\frac12-\frac xN}\log\pa{\frac12-\frac xN}+\pa{\frac12+\frac xN}\log\pa{\frac12+\frac xN}}.\]
(Nel caso di prima avremmo $r=\frac1{N_a}\pa{\frac{N_a}2-x}=\frac12-\frac x{N_a}$, da cui
\[S_i\simeq -N_a C\pa{r\log r+(1-r)\log (1-r)}\])

Per quanto riguarda lo stato finale il numero di microstati possibili ora \`e ogni combinazione di particelle nei due contenitori, $2^{N_a}$ possibilit\`a in totale, dunque
\[S_f=CN_a\log 2,\]
dunque
\[\Delta S=S_f-S_i=N_AC\pa{r\log r+(1-r)\log(1-r)+\log 2}\]
Se la costante $C$ la chiamiamo ``costante di Boltzmann" ricaviamo di nuovo effettivamente $S=k\log \Omega$.






Fissiamo la temperatura e consideriamo una espansione $V\to V+dV$. Come varia $\Omega$?\\
Mi aspetto qualcosa del tipo
\[\frac{\Omega_f}{\Omega_i}=\frac{(V+dV)^N}{V^N}=\pa{1+\frac{dV}V}^N\]
Stiamo considerando il modello di gas perfetto, quindi $dT=0\implies dU=0$, dunque
\[dV=\frac{\delta Q}p,\]
da cui
\[\frac{dV}V=\frac{\delta Q}{pV}=\frac{\delta Q}{nRT}=\frac{\delta Q}{Nk_b T}\]

Quindi verifichiamo che l'entropia di Boltzmann verifica la definizione di entropia che avevamo dato:
\[\Delta S=k_b\log\pa{\frac{\Omega_f}{\Omega_i}}=k_b N\log\pa{1+\frac{\delta Q}{Nk_b T}}\approx k_bN\frac{\delta Q}{Nk_bT}=\frac{\delta Q}T\]


Consideriamo ora una isocora e cambiamo la temperatura:
\[\ps{E_K}=\frac32k_bT\]

\[\frac12m\ps{v_x^2}=\frac12 kT\implies \ps{v_x^2}=\frac{k_bT}m,\]
inoltre per isotropia $\ps{v_x}$, quindi $\sqrt{\frac{k_bT}m}$ \`e la deviazione standard di $v_x$.
Quindi $v$ per una particella ha una deviazione standard nell'ordine di $\pa{\frac{k_bT}m}^{3/2}$ quindi nell'insieme si ha che $\ps{v}\propto T^{3N/2}$.

Quindi per questa trasformazione
\[\frac{\Omega_f}{\Omega_i}=\pa{1+\frac{dT}T}^{3N/2},\]
da cui
\[\Delta S=\frac{3N}2k_b\log\pa{1+\frac{dT}T}\approx \frac{3Nk_b}2\frac{dT}T=\frac{C_VdT}T=\frac{dU}T\pasgnl={isocora}\frac{\delta Q}T\]



\section{Informazione}
\begin{definition}[Informazione]
Sia $X$ variabile aleatoria discreta che pu\`o assumere $N$ valori $x_1,\cdots, x_N$ con densit\`a di probabilit\`a $P_i$.\\
Definiamo l'\textbf{informazione} derivante dal fatto che l'evento $x_i$ sia accaduto come
\[I_i=-\log P_i\]
\end{definition}
Vogliamo definire $\Hc(\cpa{P_i})$ come ``l'informazione che mi manca per capire l'esito data una distribuzione di probabilit\`a". Imponiamo alcune propriet\`a:
\begin{itemize}
\item $\Hc$ deve essere continua nelle $P_i$
\item Se per ogni $P_i=\frac1N$, $\Hc$ deve essere monotona e crescente in $N$.
\item [(Consistenza)\ $\bullet$] Sia $\pi$ una partizione di $N$ e per ogni elemento $g\in \pi$ sia $P_g=\sum_{i\in g}P_i$. Allora
\[\Hc(\cpa{P_i})=\Hc(\cpa{P_g}_{g\in \pi})+\sum_{g\in \pi} P_g\Hc(\cpa{P(x_i\mid g)})\]
\end{itemize}
\begin{theorem}
La funzione $\Hc$ deve assumere la forma
\[\Hc(\cpa{P_i})=-C\sum_i P_i\log(P_i).\]
Questa funzione di dice \textbf{entropia di Shannon/Gibbs}.
\end{theorem}
\begin{proof}
Consideriamo due casi
\setlength{\leftmargini}{0cm}
\begin{itemize}
\item[$\boxed{P_i=1/N}$] Sia $\Hc(\cpa{N\ii,\cdots, N\ii})=F(N)$. Consideriamo ora $n$ gruppi equiprobabili. Ogni gruppo $g$ contiene $N/n$ eventi, quindi $P_g=\frac1n$ e $P(x_i\mid g)=\frac nN$. Osserviamo dunque che $\Hc(\cpa{P(x_i\mid g)})=F(M/n)$. Per consistenza
\[F(N)=F(n)+\sum_n\frac1nF(N/n)=F(n)+F(N/n).\] 
\item Siano $s,t>1$ interi positivi e notiamo che esistono $\al,\beta$ interi tali che
\[\frac\al\beta\leq\frac{\log s}{\log t}<\frac{\al+1}\beta\implies t^\al\leq s^\beta<t^{\al+1}.\]
Per monotonia
\[F(t^\al)\leq F(s^\beta)<F(t^{\al+1}).\]
Per la propriet\`a mostrata nel caso particolare
\[\frac\al\beta\leq\frac{F(s)}{F(t)}<\frac{\al+1}\beta\implies t^\al\leq s^\beta<t^{\al+1},\]
dunque
\[\abs{\frac{F(s)}{F(t)}-\frac{\log s}{\log t}}\leq \frac1\beta,\]
quindi $F(s)=C\log s$ per una qualche costante $C$.
\item[$\boxed{\text{generale}}$] Sia $N_g=\#g$. Notiamo che $P_g=\frac{N_g}N$ e che $P(x_i\mid g)=\frac1{N_g}$. Osserviamo che
\[\Hc(\cpa{P_i})=F(N)=\Hc(\cpa{P_g})+\sum_g P_g F(N_g),\]
da cui
\begin{align*}
\Hc(\cpa{P_g})=& F(N)-\sum_g P_g F(N_g)=\sum_g P_g(F(N)-F(N_g))=\\
=& C\sum_g P_g\log(N/N_g)=\\
=&-C\sum_g P_g\log(P_g).
\end{align*}
\end{itemize}
\setlength{\leftmargini}{0.5cm}
\end{proof}

\begin{remark}
L'entropia \`e la media pesata del logaritmo delle probabilit\`a nella distribuzione a meno di costante.
\end{remark}

\begin{remark}
Se $P_i=1/N$ allora \[\Hc(\cpa{P_i})=-C\sum_i \frac1N\log\frac1N=-C\log N,\]
che a meno della notazione \`e l'equivalente di $S=k_b\log \Omega$.
\end{remark}


\subsection{Principio di massima entropia}
Consideriamo un sistema con $N$ stati e nessun vincolo. Sia $P_i$ la probabilit\`a dello stato $i$. Vogliamo trovare i $P_i$ che massimizzano $S$ sapendo che $\sum_i P_i=1$:\\
$S=-k_b\sum_i P_i\log P_i$. Per moltiplicatori di lagrange vogliamo massimizzare $S+\al \sum_i P_i$, cio\`e
\[0=\pp{P_i}{}(S+\al \sum_i P_i)=-k_b............\]


Consideriamo ora un vincolo $\ps{f(x_i)}=\sum_i P_i f(x_i)=cost.$

********************************


$U=\ps{E}$, $S=k\log Z-\frac UT$

\[P_i=\frac12 e^{\frac{E(x_i)}{k_bT}}\]






\section{Terzo principio}
\begin{fact}[Terzo principio della termodinamica]
\textbf{In un processo reversibile isotermo $\lim_{T\to 0}\Delta S=0$.}
\end{fact}
\begin{remark}
Stiamo dicendo che le isoterme per $T$ vicino a $0$ si avvicinano ad essere adiabatiche.
\end{remark}

\begin{remark}
Moralmente il principio dice che \`e difficile raffreddare verso temperature vicine allo 0 assoluto.
\end{remark}

\begin{remark}
Possiamo riformulare il principio affermando che ogni sistema ha la stessa entropia allo zero assoluto.
\end{remark}